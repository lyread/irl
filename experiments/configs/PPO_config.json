{
    "Algorithm": {
        "policy": "MLP",
        "actor_config": {
            "input_dim": 2,
            "hidden_dim": 128,
            "output_dim": 4,
            "activation_fn": "relu",
            "output_probs": true
        },
        "critic_config": {
            "input_dim": 2,
            "hidden_dim": 128,
            "output_dim": 1,
            "activation_fn": "relu",
            "output_probs": false
        },
        "name": "PPO",
        "exploration": "ppo",
        "learning_rate_a": 0.0003,
        "learning_rate_c": 0.0003,
        "discount_factor": 0.99,
        "gae_lambda": 0.95,
        "policy_clip": 0.2,
        "rollout_capacity": 200,
        "batch_size": 20,
        "n_epochs": 5,
        "device": "cpu",
        "tensorboard": true,
        "model_path": "tmp/logs/models/PPO/"
    },
    "Environment": {
        "height": 4,
        "width": 12,
        "punishment": true,
        "normalize": true
    },
    "Agent": {
        "max_episode_length": 30,
        "test_every": 10
    },
    "Experiment": {
        "algorithm": "PPO",
        "env": "Cliff",
        "num_episodes": 2000,
        "num_runs": 2
    },
    "Logger": {
        "logdir": "tmp",
        "categories": {
            "learning_rewards": [],
            "learning_steps": [],
            "learning_discounted_rewards": [],
            "learning_state_action_pairs": [],
            "learning_state_visit_matrix": [
                4,
                12
            ],
            "learning_success": [],
            "learning_collision": [],
            "learning_fell_into_cliff": [],
            "test_rewards": [],
            "test_steps": [],
            "test_discounted_rewards": [],
            "test_state_action_pairs": [],
            "test_state_visit_matrix": [
                4,
                12
            ],
            "test_success": [],
            "test_collision": [],
            "test_fell_into_cliff": [],
            "cumulated_learning_steps": [],
            "cumulated_test_steps": []
        },
        "multiple_run_categories": {
            "learning_rewards": [],
            "learning_steps": [],
            "learning_discounted_rewards": [],
            "learning_state_visit_matrix": [],
            "learning_success": [],
            "learning_collision": [],
            "learning_fell_into_cliff": [],
            "test_rewards": [],
            "test_steps": [],
            "test_discounted_rewards": [],
            "test_state_visit_matrix": [],
            "test_success": [],
            "test_collision": [],
            "test_fell_into_cliff": [],
            "cumulated_learning_steps": [],
            "cumulated_test_steps": []
        }
    }
}